{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e898be79-be14-4a83-a98f-ffd8b175a248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Loading the models\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "st.set_page_config(page_title=\"News Q&A\", page_icon=\"ðŸ“°\", layout=\"wide\")\n",
    "\n",
    "st.title('ðŸ“° News Q&A')\n",
    "st.write('Enter URLs of news articles and questions to get answers.')\n",
    "\n",
    "def is_valid_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.scheme) and bool(parsed.netloc)\n",
    "\n",
    "def fetch_article(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        text = ' '.join([para.get_text() for para in paragraphs])\n",
    "        return text\n",
    "    except requests.RequestException as e:\n",
    "        st.error(f\"Error fetching article from {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def embed_articles(articles):\n",
    "    all_paragraphs = []\n",
    "    all_embeddings = []\n",
    "    article_sources = []\n",
    "    \n",
    "    for url, article in articles:\n",
    "        if article.strip():\n",
    "            paragraphs = article.split('\\n')\n",
    "            embeddings = model.encode(paragraphs)\n",
    "            all_paragraphs.extend(paragraphs)\n",
    "            all_embeddings.extend(embeddings)\n",
    "            article_sources.extend([url] * len(paragraphs))\n",
    "        \n",
    "    return all_paragraphs, np.array(all_embeddings), article_sources\n",
    "\n",
    "def create_index(embeddings):\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])  # Dimension of embeddings\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "import re\n",
    "\n",
    "def get_answer(question, all_paragraphs, index, article_sources, max_sentences=3):\n",
    "    question_embedding = model.encode([question])\n",
    "    D, I = index.search(np.array(question_embedding), k=5)\n",
    "    \n",
    "    candidate_paragraphs = [all_paragraphs[i] for i in I[0]]\n",
    "    candidate_sources = [article_sources[i] for i in I[0]]\n",
    "    \n",
    "    best_answer = None\n",
    "    best_source = None\n",
    "    best_score = 0\n",
    "    best_paragraph = None\n",
    "    \n",
    "    for paragraph, source in zip(candidate_paragraphs, candidate_sources):\n",
    "        if not paragraph.strip():\n",
    "            continue\n",
    "        result = qa_pipeline(question=question, context=paragraph)\n",
    "        if result['score'] > best_score:\n",
    "            best_score = result['score']\n",
    "            best_answer = result['answer']\n",
    "            best_source = source\n",
    "            \n",
    "            # Split the paragraph into sentences\n",
    "            sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', paragraph)\n",
    "            # Take the first few sentences (max_sentences)\n",
    "            best_paragraph = ' '.join(sentences[:max_sentences])\n",
    "    \n",
    "    return best_answer, best_source, best_paragraph\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .main {\n",
    "        background-color: #BB9AB1;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    .sidebar .sidebar-content {\n",
    "        background-color: #987D9A;\n",
    "    }\n",
    "   \n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "# Ensure the session state has a key for tracking the display state of the source paragraph\n",
    "# Layout\n",
    "st.sidebar.title(\"User Input\")\n",
    "url1 = st.sidebar.text_input('Enter news article URL 1')\n",
    "url2 = st.sidebar.text_input('Enter news article URL 2')\n",
    "url3 = st.sidebar.text_input('Enter news article URL 3')\n",
    "question = st.sidebar.text_input('Enter your question')\n",
    "\n",
    "# Add a checkbox to toggle the display of the source paragraph\n",
    "show_source_paragraph = st.sidebar.checkbox('Show Source Paragraph')\n",
    "\n",
    "if st.sidebar.button('Get Answer'):\n",
    "    if question:\n",
    "        valid_urls = [url for url in [url1, url2, url3] if is_valid_url(url)]\n",
    "        if valid_urls:\n",
    "            with st.spinner('Fetching articles and generating answer...'):\n",
    "                articles = [(url, fetch_article(url)) for url in valid_urls]\n",
    "                all_paragraphs, all_embeddings, article_sources = embed_articles(articles)\n",
    "                \n",
    "                if all_paragraphs:\n",
    "                    index = create_index(all_embeddings)\n",
    "                    answer, source, best_paragraph = get_answer(question, all_paragraphs, index, article_sources)\n",
    "                    if answer:\n",
    "                        st.success('Answer generated successfully!')\n",
    "                        st.write('### Answer:', answer)\n",
    "                        if show_source_paragraph:  # Conditionally display the source paragraph\n",
    "                            st.write('### Source Paragraph:', best_paragraph)\n",
    "                        st.write('### Source URL:', source)\n",
    "                    else:\n",
    "                        st.error('No answer could be found.')\n",
    "                else:\n",
    "                    st.error('No valid content was found in the provided articles.')\n",
    "        else:\n",
    "            st.error('Please provide valid URLs.')\n",
    "    else:\n",
    "        st.error('Please provide a question.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2034dc50-fc21-4751-8433-55c94585b2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', 'app.py']>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.Popen(['streamlit', 'run', 'app.py'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
